{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16086bdd-5408-4bf3-abbe-fcdf5cb713f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from time import time\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "# from https://github.com/Po-Hsun-Su/pytorch-ssim\n",
    "import pytorch_ssim as ssim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c57ef-362b-48ec-942b-50cf16dbd3b1",
   "metadata": {},
   "source": [
    "# Music Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26705d24-0784-4afb-82bc-cc6c785c6efe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "musics = np.load('omiir_music.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9454d6-6911-415f-834f-018d42a2b42f",
   "metadata": {},
   "source": [
    "## Preparation - Resampling, STFT, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6153c0b0-3956-40f1-914e-19b5e96be061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_downsampling(target_sr, stft=False, stft_window=256):\n",
    "    for version in musics.keys():\n",
    "        for mid, music in musics[version].items():\n",
    "            wav = (music['wav'] - music['wav'].mean())/music['wav'].std()\n",
    "            music['wav-low'] = librosa.resample(wav, orig_sr=music['rate'], target_sr=target_sr)\n",
    "            music['rate-low'] = target_sr\n",
    "            music['sample-low'] = music['wav-low'].shape[0]\n",
    "            music['onset-low'] = np.round(music['onset']/music['rate']*music['rate-low']).astype(int)\n",
    "            music['onset_woc-low'] = np.round(music['onset_woc']/music['rate']*music['rate-low']).astype(int)\n",
    "            music['beat-low'] = np.round(music['beat']/music['rate']*music['rate-low']).astype(int)\n",
    "            music['beat_woc-low'] = np.round(music['beat_woc']/music['rate']*music['rate-low']).astype(int)\n",
    "            \n",
    "            if stft:\n",
    "                music['stft-low'] = librosa.stft(music['wav-low'], hop_length=stft_window, win_length=stft_window)\n",
    "\n",
    "            music['audio'] = Audio(data=wav, rate=music['rate'])\n",
    "            music['audio-low'] = Audio(data=librosa.resample(music['wav-low'], orig_sr=target_sr, target_sr=music['rate']), rate=music['rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58c9638-289c-4d7e-8621-c6738ec23646",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EEG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8cebcc7-96bc-4615-b487-277a35fd004f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file omiir_all_preprocessed.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_1384\\1980649454.py:1: RuntimeWarning: This filename (omiir_all_preprocessed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  data_eeg = mne.io.read_raw_fif('omiir_all_preprocessed.fif', preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 1287637 =      0.000 ... 20119.328 secs\n",
      "Ready.\n",
      "Reading 0 ... 1287637  =      0.000 ... 20119.328 secs...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>March 06, 2015  11:30:43 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>67 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>64 EEG, 4 EOG, 1 Stimulus, 1 misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>EXG1, EXG2, EXG3, EXG4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>64.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.50 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>32.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>omiir_all_preprocessed.fif</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>05:35:20 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | omiir_all_preprocessed.fif, 70 x 1287638 (20119.3 s), ~687.8 MB, data loaded>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_eeg = mne.io.read_raw_fif('omiir_all_preprocessed.fif', preload=True)\n",
    "EEG_RATE = data_eeg.info['sfreq']\n",
    "data_eeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c528a9-d08a-4de0-843a-0a28162b3f0c",
   "metadata": {},
   "source": [
    "## Preprocess - Standardization + Trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa60f24f-2e22-41d5-8a15-bb3e2a92015b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size in memory: 659.27 mb\n"
     ]
    }
   ],
   "source": [
    "data_eeg_raw = data_eeg.get_data('eeg')\n",
    "\n",
    "print(f\"Size in memory: {data_eeg_raw.size * data_eeg_raw.itemsize / 1e6:.2f} mb\")\n",
    "\n",
    "subids_idx = data_eeg.get_data('SUBID').reshape(-1).astype(int)\n",
    "subids = sorted(set(subids_idx))\n",
    "\n",
    "z_cutoff = 2\n",
    "start_idx = 0\n",
    "for subid in subids:\n",
    "    end_idx = np.searchsorted(subids_idx, subid, side='right')\n",
    "    mean = data_eeg_raw[:, start_idx:end_idx].mean(axis=1)\n",
    "    std = data_eeg_raw[:, start_idx:end_idx].std(axis=1)\n",
    "    t = data_eeg_raw[:, start_idx:end_idx].transpose()\n",
    "    standardized = ((t - mean)/std).transpose()\n",
    "    \n",
    "    data_eeg_raw[:, start_idx:end_idx] = np.clip(standardized, a_min=-z_cutoff, a_max=z_cutoff)/z_cutoff  # Clip + Scale to -1>1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f2b98d-ece8-414d-ba68-b8977d56f61f",
   "metadata": {},
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34e86117-62fb-4a54-9a16-9c851b31ec80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sep_event_id(eid):\n",
    "    '''\n",
    "        return: music-id(str), trial_type(int), version(str)\n",
    "    '''\n",
    "    return f'{int(str(eid)[:-2]):02d}', int(str(eid)[-2]), f'v{str(eid)[-1]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ebb6353-298c-45ad-9c8d-5fd40453da04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1620 events found\n",
      "Event IDs: [ 111  112  121  122  131  132  211  212  221  222  231  232  311  312\n",
      "  321  322  331  332  411  412  421  422  431  432 1111 1112 1121 1122\n",
      " 1131 1132 1211 1212 1221 1222 1231 1232 1311 1312 1321 1322 1331 1332\n",
      " 1411 1412 1421 1422 1431 1432 2111 2112 2121 2122 2131 2132 2211 2212\n",
      " 2221 2222 2231 2232 2311 2312 2321 2322 2331 2332 2411 2412 2421 2422\n",
      " 2431 2432]\n"
     ]
    }
   ],
   "source": [
    "data_events = mne.find_events(data_eeg, initial_event=True)\n",
    "data_events_info = np.hstack([\n",
    "    data_events[:, 0].reshape(-1, 1),  # start\n",
    "    np.concatenate([data_events[1:, 0], [data_eeg.last_samp - 1]]).reshape(-1, 1), # end\n",
    "    np.asarray([sep_event_id(eid) for eid in data_events[:, 2]], dtype='object'),  # music-id, trial_type, version\n",
    "    data_eeg.get_data('SUBID')[0, data_events[:, 0]].astype(int).reshape(-1, 1)  # subid\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5756e53b-5464-4153-b306-5c85992e7dd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "131302c3-aff2-4679-a9d5-720a201b11bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx_EEG_START, idx_EEG_STOP, idx_MID, idx_TRIAL, idx_VERSION, idx_SUBID = 0, 1, 2, 3, 4, 5\n",
    "TRIAL = dict(\n",
    "    LISTEN=1,\n",
    "    IMAGE=2,\n",
    "    IMAGE_WOC=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e5f2db2-d1f2-46ff-a3f8-2262a8186348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def events_iter(batch_size, filter_trial_type=None, filter_subject_ids=None, custom_filter=None, shuffle=False):\n",
    "    # Filter\n",
    "    events_filter = np.ones(data_events_info.shape[0]).astype(bool)\n",
    "    if filter_trial_type is not None:\n",
    "        events_filter &= data_events_info[:, idx_TRIAL] == filter_trial_type\n",
    "    if filter_subject_ids is not None:\n",
    "        events_filter &= np.isin(data_events_info[:, idx_SUBID], filter_subject_ids)\n",
    "    if custom_filter is not None:\n",
    "        events_filter &= custom_filter\n",
    "    \n",
    "    events_idx = np.argwhere(events_filter).reshape(-1)\n",
    "    \n",
    "    # Shuffle\n",
    "    if shuffle:\n",
    "        np.random.shuffle(events_idx)\n",
    "    \n",
    "    # Return\n",
    "    res = []\n",
    "    for i in range(0, events_idx.shape[0], batch_size):\n",
    "        j = min(events_idx.shape[0], i+batch_size)\n",
    "        res.append(events_idx[i: j])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c447bb99-2d60-447e-baa9-cbf4ed42da8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def array_iter(arr, shuffle=False, extend=None):\n",
    "    indices = np.arange(arr.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    \n",
    "    res = []\n",
    "    for idx in indices:\n",
    "        res.append(arr[idx])\n",
    "    \n",
    "    if extend is not None:\n",
    "        length = len(indices)\n",
    "        for idx in range(extend-length):\n",
    "            res.append(arr[indices[idx % length]])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00825e80-4da7-47da-b6c9-0ad9b64250d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def padding(arr, window_length, axis=0):\n",
    "    if arr.shape[axis] < window_length:\n",
    "        return np.pad(arr, [(0, window_length-d) if i == axis else (0, 0) for i, d in enumerate(arr.shape)], constant_values=(0))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ccd5f09-78c2-485e-afc9-09c87f60c6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_iteration(indices, window_length, testing_mode=False, shuffle=True):\n",
    "    io_indices = []\n",
    "    music_data = []\n",
    "    for eeg_start, eeg_stop, mid, _, version, _ in data_events_info[indices]:\n",
    "        music = musics[version][mid]\n",
    "        music_data.append(music['wav-low'])\n",
    "        music_window_length = window_length/EEG_RATE*music['rate-low']\n",
    "        if not music_window_length.is_integer():\n",
    "            print(f'Warning: music_window_length is not integer ({music_window_length}), will be floored to {int(music_window_length)}')\n",
    "        music_window_length = int(music_window_length)\n",
    "\n",
    "        eeg_indices = [\n",
    "            np.arange(eeg_start, eeg_stop, window_length),  # EEG-start\n",
    "            np.concatenate([np.arange(eeg_start + window_length, eeg_stop, window_length), [eeg_stop]]) # EEG-stop\n",
    "        ]\n",
    "        \n",
    "        cutoff = eeg_indices[0].shape[0]  # Bug: music fraction after eeg end.\n",
    "        music_indices = [\n",
    "            np.arange(0, music['sample-low'], music_window_length)[:cutoff],  # Music-start\n",
    "            np.concatenate([np.arange(music_window_length, music['sample-low'], music_window_length), [(music['sample-low'])]])[:cutoff]  # Music-stop\n",
    "        ]\n",
    "        start_stop = np.stack(eeg_indices + music_indices, axis=1)\n",
    "        io_indices.append(start_stop)\n",
    "\n",
    "    max_iter = max(map(lambda x: len(x), io_indices))\n",
    "    io_list = [array_iter(io, shuffle=shuffle, extend=None if testing_mode else max_iter) for io in io_indices]\n",
    "    \n",
    "    return max_iter, io_list, music_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2daa5a8-326a-46c4-a216-c80699892f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_iter(indices, window_length, shuffle=True):\n",
    "    max_iter, io_list, music_data = make_iteration(indices, window_length, shuffle=shuffle)\n",
    "\n",
    "    batch_data = []\n",
    "    for it in range(max_iter):\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        for io, wav in zip(io_list, music_data):\n",
    "            sample_start, sample_stop, music_start, music_stop = io[it]\n",
    "            batch_input.append(padding(data_eeg_raw[:, sample_start:sample_stop], window_length=window_length, axis=1))\n",
    "            batch_output.append(padding(wav[music_start: music_stop], window_length=music_window_length))\n",
    "        batch_data.append((np.stack(batch_input), np.stack(batch_output)))\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06bb145b-ed5a-4f73-a684-27e28e4e9120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def testing_iter(indices, window_length, shuffle=False):\n",
    "    _, io_list, music_data = make_iteration(indices, window_length, testing_mode=True, shuffle=shuffle)\n",
    "    \n",
    "    batch_data = []\n",
    "    for io, wav in zip(io_list, music_data):\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        for sample_start, sample_stop, music_start, music_stop in io:\n",
    "            batch_input.append(padding(data_eeg_raw[:, sample_start:sample_stop], window_length=window_length, axis=1))\n",
    "            batch_output.append(padding(wav[music_start: music_stop], window_length=music_window_length))\n",
    "        batch_data.append((np.stack(batch_input), np.stack(batch_output)))\n",
    "        \n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e3f3a-3195-4121-b226-903e0d0781f6",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c676e9-5c3d-4d08-983b-ab30f4c4ffcc",
   "metadata": {},
   "source": [
    "```\n",
    "Training Set - SUB[MID(------), (------),        ]\n",
    "Testing Set -  SUB[                   NEW(------)]\n",
    "           NEW-SUB[(------),            ,(------)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f211555-b484-4e2f-ae38-c156f48c1391",
   "metadata": {
    "tags": []
   },
   "source": [
    "SUBJECT v1 {1, 4, 6, 7} v2 {9, 11, 12, 13, 14}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0735e889-a7e7-4cb8-a43a-f881c62c8c57",
   "metadata": {},
   "source": [
    "| ID | Name                                | Meter | Length | Tempo   | Train/Test | Note |\n",
    "|----|-------------------------------------|-------|--------|---------|------------|------|\n",
    "|  1 | Chim Chim Cheree (lyrics)           |   3/4 |  13.3s | 212 BPM | Mixed      | \n",
    "|  2 | TakeMe Out to the Ballgame (lyrics) |   3/4 |   7.7s | 189 BPM | Mixed      | \n",
    "|  3 | Jingle Bells (lyrics)               |   4/4 |   9.7s | 200 BPM | Mixed      | Train/Test: Training Subject/Testing Only Subject (v1 == v2)\n",
    "|  4 | Mary Had a Little Lamb (lyrics)     |   4/4 |  11.6s | 160 BPM |  Test Only | (v1 == v2) > Unknown Song Experiment\n",
    "| 11 | Chim Chim Cheree                    |   3/4 |  13.5s | 212 BPM | Mixed      | No lyrics\n",
    "| 12 | TakeMe Out to the Ballgame          |   3/4 |   7.7s | 189 BPM | Mixed      | No lyrics\n",
    "| 13 | Jingle Bells                        |   4/4 |   9.0s | 200 BPM | Mixed      | Nixing - No lyrics (v1 == v2)\n",
    "| 14 | Mary Had a Little Lamb              |   4/4 |  12.2s | 160 BPM |  Test Only | Piano -  No lyrics (v1 == v2) > Unknown Song Experiment\n",
    "| 21 | EmperorWaltz                        |   3/4 |   8.3s | 178 BPM | Mixed      | Orchestra\n",
    "| 22 | Hedwig’s Theme (Harry Potter)       |   3/4 |  16.0s | 166 BPM | Mixed      | \"Celesta\" > Instrument Experiment\n",
    "| 23 | ImperialMarch (StarWars Theme)      |   4/4 |   9.2s | 104 BPM | Mixed      | \"Trombone\" > Instrument Experiment\n",
    "| 24 | Eine Kleine Nachtmusik              |   4/4 |   6.9s | 140 BPM | Mixed      | \"Violin\" > Instrument Experiment\n",
    "|    |                                mean |       |  10.4s | 176 BPM |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc294a3d-95b5-420c-bffc-e1f73e3eb033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_IDS = [\n",
    "    ('02', 1),\n",
    "    ('03', 1),\n",
    "    ('12', 1),\n",
    "    ('13', 1),\n",
    "    ('21', 1),\n",
    "    ('23', 1),\n",
    "    ('24', 1),\n",
    "    \n",
    "    ('01', 4),\n",
    "    ('03', 4),\n",
    "    ('11', 4),\n",
    "    ('13', 4),\n",
    "    ('21', 4),\n",
    "    ('22', 4),\n",
    "    ('24', 4),\n",
    "    \n",
    "    ('01', 6),\n",
    "    ('02', 6),\n",
    "    ('11', 6),\n",
    "    ('12', 6),\n",
    "    ('21', 6),\n",
    "    ('22', 6),\n",
    "    ('23', 6),\n",
    "    \n",
    "    ('02', 7),\n",
    "    ('03', 7),\n",
    "    ('12', 7),\n",
    "    ('13', 7),\n",
    "    ('22', 7),\n",
    "    ('23', 7),\n",
    "    ('24', 7),\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f5666ab-2c37-49bd-9c7f-96f8f6010d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VALID_IDS = [\n",
    "    ('01', 1),\n",
    "    ('11', 1),\n",
    "    ('22', 1),\n",
    "    \n",
    "    ('02', 4),\n",
    "    ('12', 4),\n",
    "    ('23', 4),\n",
    "    \n",
    "    ('03', 6),\n",
    "    ('13', 6),\n",
    "    ('24', 6), \n",
    "    \n",
    "    ('01', 7),\n",
    "    ('11', 7),\n",
    "    ('21', 7),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2dc3c74c-1b99-437e-8b2b-c3992c27a6ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_NEW_SUB = [\n",
    "    # New Subject (SUBID=9)\n",
    "    ('01', 9),\n",
    "    ('02', 9),\n",
    "    ('03', 9),\n",
    "    ('11', 9),\n",
    "    ('12', 9),\n",
    "    ('13', 9),\n",
    "    ('21', 9),\n",
    "    ('22', 9),\n",
    "    ('23', 9),\n",
    "    \n",
    "    # New Subject (SUBID=11)\n",
    "    ('01', 11),\n",
    "    ('02', 11),\n",
    "    ('03', 11),\n",
    "    ('11', 11),\n",
    "    ('12', 11),\n",
    "    ('13', 11),\n",
    "    ('21', 11),\n",
    "    ('22', 11),\n",
    "    ('23', 11),\n",
    "]\n",
    "\n",
    "TEST_NEW_MUSIC = [\n",
    "    # New Music '04' '14'\n",
    "    ('04', 1),\n",
    "    ('04', 4),\n",
    "    ('04', 6),\n",
    "    ('04', 9),\n",
    "    ('04', 11),\n",
    "    \n",
    "    ('14', 1),\n",
    "    ('14', 4),\n",
    "    ('14', 6),\n",
    "    ('14', 9),\n",
    "    ('14', 11),\n",
    "]\n",
    "\n",
    "TEST_INSTRUMENT_CELESTA = [\n",
    "    # Celesta\n",
    "    ('22', 9),\n",
    "    ('22', 11),\n",
    "]\n",
    "TEST_INSTRUMENT_TROMBONE = [\n",
    "    # Trombone\n",
    "    ('23', 9),\n",
    "    ('23', 11),\n",
    "]\n",
    "TEST_INSTRUMENT_VIOLIN = [\n",
    "    # Violin\n",
    "    ('24', 9),\n",
    "    ('24', 11),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8962f683-e45c-45d6-8351-69240d068526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_custom_filter = list(map(lambda x: tuple(x) in TRAIN_IDS, data_events_info[:, [idx_MID, idx_SUBID]]))\n",
    "valid_custom_filter = list(map(lambda x: tuple(x) in VALID_IDS, data_events_info[:, [idx_MID, idx_SUBID]]))\n",
    "\n",
    "experiments_list = [TEST_NEW_SUB, TEST_NEW_MUSIC, TEST_INSTRUMENT_CELESTA, TEST_INSTRUMENT_TROMBONE, TEST_INSTRUMENT_VIOLIN]\n",
    "ID_TEST_NEW_SUB    = 0\n",
    "ID_TEST_NEW_MUSIC  = 1\n",
    "ID_TEST_INSTRUMENT_CELESTA  = 2\n",
    "ID_TEST_INSTRUMENT_TROMBONE = 3\n",
    "ID_TEST_INSTRUMENT_VIOLIN   = 4\n",
    "\n",
    "test_filter_list = [list(map(lambda x: tuple(x) in exp, data_events_info[:, [idx_MID, idx_SUBID]])) for exp in experiments_list]\n",
    "# These filter will be merged with filter_trial_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87f6ba6-7fcd-469a-9731-b4ebdd8b076e",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2232ab68-4d9d-44a1-89cd-b3a36d5a37ce",
   "metadata": {},
   "source": [
    "## MLP (WAV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e5daf-66b5-45a6-a10f-da57777099c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linears = nn.Sequential(\n",
    "            nn.Linear(input_size, 2 ** 10),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm1d(2 ** 10),\n",
    "            nn.Linear(2 ** 10, 2 ** 9),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm1d(2 ** 9),\n",
    "            nn.Linear(2 ** 9, 2 ** 8),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm1d(2 ** 8),\n",
    "            nn.Linear(2 ** 8, output_size),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.linears(X)\n",
    "    \n",
    "    @staticmethod\n",
    "    def transform_input(X):\n",
    "        # batch_input = (batch_size, number_channel, window_length)\n",
    "        # target (batch, input)\n",
    "        return X.reshape(X.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549d7167-97ce-4128-83ee-5563119d0584",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BiLSTM (WAV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9600c408-e676-4f85-9efe-428414e8bd83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, feature_size, num_layer, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linears = nn.Sequential(\n",
    "            nn.Linear(input_size, feature_size),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=feature_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layer,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_size*2, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size//2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size//2, output_size),\n",
    "        )\n",
    "    \n",
    "    def forward(self, X, state=None):\n",
    "        out_1 = self.linears(X)\n",
    "        state = None\n",
    "        out_2 = []\n",
    "        for inp in out_1:\n",
    "            out, (hn, cn) = self.lstm(inp, state)\n",
    "            out_2.append(out)\n",
    "        out_2 = self.tanh(th.stack(out_2))\n",
    "        \n",
    "        out_3 = self.mlp(out_2).flatten(start_dim=1)\n",
    "        \n",
    "        return out_3, (hn, cn)\n",
    "    \n",
    "    @staticmethod\n",
    "    def transform_input(X):\n",
    "        # batch_input = (batch_size, number_channel, window_length)\n",
    "        # target (batch, length, input)\n",
    "        return X.transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd5e48-714a-4317-9716-cdb0b728bb66",
   "metadata": {},
   "source": [
    "# Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "18f1cc6a-715b-48f4-a74d-15b102fac862",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Music Data\n",
    "music_rate = 64\n",
    "enable_stft = False\n",
    "stft_window = None\n",
    "\n",
    "# Data\n",
    "trial_type = 'IMAGE' # 'LISTEN' 'IMAGE', 'IMAGE_WOC' (Need time_stretch function)\n",
    "filter_trial_type = TRIAL[trial_type]\n",
    "sub_ids = None\n",
    "\n",
    "# Model\n",
    "batch_size = 16\n",
    "number_channel = 64\n",
    "window_length = 32\n",
    "feature_size = 256\n",
    "hidden_size = 256\n",
    "num_layer = 4\n",
    "\n",
    "# Train/Test\n",
    "num_iteration = 200\n",
    "\n",
    "# State\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "# DO NOT CHANGE\n",
    "prepare_downsampling(target_sr=music_rate, stft=enable_stft, stft_window=stft_window)\n",
    "music_window_length = window_length/EEG_RATE*music_rate\n",
    "if not music_window_length.is_integer():\n",
    "    raise Exception('Configure Error: music_window_length must be integer')\n",
    "music_window_length = int(music_window_length)\n",
    "\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e888ae3a-6fb4-40dc-aa48-922382574e8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5fc70de4-362f-4af5-99c6-fab041e9c88e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = th.device('cuda' if th.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "99b0830a-2e71-4d4f-aab6-3d0453e5dd7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTMModel                                [1, 32]                   --\n",
       "├─Sequential: 1-1                        [1, 32, 256]              --\n",
       "│    └─Linear: 2-1                       [1, 32, 256]              16,640\n",
       "│    └─Tanh: 2-2                         [1, 32, 256]              --\n",
       "├─LSTM: 1-2                              [32, 512]                 5,783,552\n",
       "├─Tanh: 1-3                              [1, 32, 512]              --\n",
       "├─Sequential: 1-4                        [1, 32, 1]                --\n",
       "│    └─Linear: 2-3                       [1, 32, 256]              131,328\n",
       "│    └─Tanh: 2-4                         [1, 32, 256]              --\n",
       "│    └─Linear: 2-5                       [1, 32, 128]              32,896\n",
       "│    └─Tanh: 2-6                         [1, 32, 128]              --\n",
       "│    └─Linear: 2-7                       [1, 32, 1]                129\n",
       "==========================================================================================\n",
       "Total params: 5,964,545\n",
       "Trainable params: 5,964,545\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 94.76\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.30\n",
       "Params size (MB): 23.86\n",
       "Estimated Total Size (MB): 24.16\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = LSTMModel(\n",
    "    input_size=number_channel,\n",
    "    feature_size=feature_size,\n",
    "    num_layer=num_layer,\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=output_size,\n",
    ").to(device)\n",
    "net_has_state = True\n",
    "MODEL = 'LSTM'\n",
    "MODEL_SIGNATURE = f'{256}-{256}-{4}'\n",
    "\n",
    "summary(net, (1, window_length, number_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd34e5-0343-4961-bba3-d05ee3e7cc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLPModel(\n",
    "    input_size=number_channel * window_length,\n",
    "    output_size=music_window_length,\n",
    ").to(device)\n",
    "net_has_state = False\n",
    "MODEL = 'MLP'\n",
    "MODEL_SIGNATURE = f'{2**10}-{2**8}'\n",
    "\n",
    "summary(net, (1, window_length * number_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88380da3-6c5a-49e0-a583-2ce330e2a654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()  # Must edit a stats_dict if change.\n",
    "optimizer = th.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26d0d86b-2c79-4a51-91b0-509854341679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ssim_criterion = ssim.SSIM(size_average=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2366aa57-1420-4be7-a7b3-e70a3a7799e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f0a2901e-eaad-46a5-9451-345ec098e7cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for indices in events_iter(\n",
    "#         batch_size=batch_size, filter_trial_type=filter_trial_type, filter_subject_ids=sub_ids,\n",
    "#         custom_filter=train_custom_filter,\n",
    "#         shuffle=True\n",
    "# ):\n",
    "#     for batch_input, batch_output in training_iter(indices, window_length=window_length, shuffle=True):\n",
    "#         X = th.Tensor(net.transform_input(batch_input)).to(device)\n",
    "#         Y = th.Tensor(batch_output).to(device)\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "afc87e8d-cdc8-4a2c-9879-fb882f9e17ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # For BiLSTM_Test (parameter tuning)\n",
    "# sample_data = training_iter(indices, window_length=window_length, shuffle=True)\n",
    "\n",
    "# sample_input = list(map(lambda x: x[0], sample_data))\n",
    "# sample_output = list(map(lambda x: x[1], sample_data))\n",
    "\n",
    "# np.save('BiLSTM_Test_data.npy', dict(\n",
    "#     batch_input=np.stack(sample_input),\n",
    "#     batch_output=np.stack(sample_output),\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92241259-89bc-42fd-b646-aa4870aab346",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8a562-a45c-4d60-8202-4fbc52ab699e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87fa83-aa01-49f8-bed0-26f106e2d812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats = []\n",
    "stats_dict = dict(\n",
    "    iteration=0,\n",
    "    trial_type=trial_type,\n",
    "    loss_mode='MAE',\n",
    "    \n",
    "    train_loss=0.0,\n",
    "    train_loss_raw=[],\n",
    "    train_epoch=0,\n",
    "    train_batch=0,\n",
    "    \n",
    "    valid_loss_raw=[],\n",
    "    valid_loss_data=[],\n",
    "    valid_loss=0.0,  # Equal micro\n",
    "    valid_loss_micro=0.0,\n",
    "    valid_loss_macro=0.0,\n",
    "    valid_epoch=0,\n",
    "    valid_batch=0,\n",
    "    valid_difference=[],\n",
    "    valid_similarity=[],\n",
    "    \n",
    "    best_loss=0.0,\n",
    "    best_iteration=None,\n",
    "    \n",
    "    best_sim=0.0,\n",
    "    best_sim_iteration=None,\n",
    "    \n",
    "    test_epoch=0,\n",
    "    test_batch=0,\n",
    "    \n",
    "    test_loss_data=dict(),\n",
    "    test_loss_raw=dict(),\n",
    "    test_loss_micro=[],\n",
    "    test_loss_macro=[],\n",
    "    test_difference_raw=dict(),\n",
    "    test_difference=[],\n",
    "    test_similarity_raw=dict(),\n",
    "    test_similarity=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f67147-fb7b-4a4e-92de-5591941f181b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_difference(ref_rec, input_rec, weightage=[0.33,0.33,0.33]):\n",
    "    ## Time domain similarity\n",
    "    ref_time = np.correlate(ref_rec,ref_rec)\n",
    "    inp_time = np.correlate(ref_rec,input_rec)\n",
    "    diff_time = abs(ref_time-inp_time)\n",
    "    \n",
    "    ## Freq domain similarity\n",
    "    ref_freq = np.correlate(np.fft.fft(ref_rec),np.fft.fft(ref_rec)) \n",
    "    inp_freq = np.correlate(np.fft.fft(ref_rec),np.fft.fft(input_rec))\n",
    "    diff_freq = abs(ref_freq-inp_freq)\n",
    "    \n",
    "    ## Power similarity\n",
    "    ref_power = np.sum(ref_rec**2)\n",
    "    inp_power = np.sum(input_rec**2)\n",
    "    diff_power = abs(ref_power-inp_power)\n",
    "    \n",
    "    return diff_time[0], diff_freq[0], diff_power, weightage[0] * diff_time[0] + weightage[1] * diff_freq[0] + weightage[2] * diff_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2447af56-9646-4566-9dc0-80c891e100de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stft_tensor(wav, n_fft=64):\n",
    "    stft = th.stft(th.Tensor(wav), n_fft=n_fft, return_complex=True)\n",
    "    return stft.view((1, 1) + tuple(stft.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb1f63b-3364-4aa7-ae97-7da9811b502d",
   "metadata": {},
   "source": [
    "## Train/Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be9ad8-26c6-4737-9820-060215bf85c1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "interation_progress = IntProgress(min=0, max=num_iteration)\n",
    "interation_progress.value = 0\n",
    "interation_progress.description = f'Iter: 0/{num_iteration}'\n",
    "display(interation_progress)\n",
    "\n",
    "train_progress = IntProgress(min=0, max=500)\n",
    "train_progress.value = 0\n",
    "max_train_epoch = '???'\n",
    "train_progress.description = f'Train 0/{max_train_epoch}'\n",
    "display(train_progress)\n",
    "\n",
    "valid_progress = IntProgress(min=0, max=100)\n",
    "valid_progress.value = 0\n",
    "max_valid_epoch = '???'\n",
    "valid_progress.description = f'Validate 0/{max_valid_epoch}'\n",
    "display(valid_progress)\n",
    "\n",
    "test_progress = IntProgress(min=0, max=100)\n",
    "test_progress.value = 0\n",
    "max_test_epoch = '???'\n",
    "test_progress.description = f'Test 0/{max_test_epoch}'\n",
    "display(test_progress)\n",
    "\n",
    "best_loss = None\n",
    "best_iter = 0\n",
    "\n",
    "best_sim = None\n",
    "best_sim_iter = 0\n",
    "\n",
    "for iteration in range(1, num_iteration + 1):\n",
    "    interation_progress.value = iteration\n",
    "    interation_progress.description = f'Iter: {iteration}/{num_iteration}'\n",
    "    \n",
    "    monitor_loss = 0\n",
    "    n_monitor = 50\n",
    "    \n",
    "    train_loss = []\n",
    "    train_epoch = 0\n",
    "    train_batch = 0\n",
    "    net.train()\n",
    "    for indices in events_iter(\n",
    "            batch_size=batch_size, filter_trial_type=filter_trial_type, filter_subject_ids=sub_ids,\n",
    "            custom_filter=train_custom_filter,\n",
    "            shuffle=True\n",
    "    ):\n",
    "        for batch_input, batch_output in training_iter(indices, window_length=window_length, shuffle=True):\n",
    "            train_epoch += 1\n",
    "            train_batch += batch_input.shape[0]\n",
    "            train_progress.value = train_epoch\n",
    "            train_progress.description = f'Train {train_epoch}/{max_train_epoch}'\n",
    "            \n",
    "            # batch_input = (batch_size, number_channel, window_length)\n",
    "            X = th.Tensor(net.transform_input(batch_input)).to(device)\n",
    "            Y = th.Tensor(batch_output).to(device)\n",
    "\n",
    "            output = net(X)\n",
    "            if net_has_state:\n",
    "                output, state = output\n",
    "            loss = criterion(output, Y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            monitor_loss += loss.item()\n",
    "            \n",
    "            if train_epoch % n_monitor == 0:\n",
    "                print(f'Iter: {iteration}, Epoch: {train_epoch}/{max_train_epoch}, MAELoss: {monitor_loss/n_monitor*1e6:.3f} / 1e6')\n",
    "                monitor_loss = 0\n",
    "    \n",
    "    train_progress.max = max_train_epoch = train_epoch\n",
    "    train_progress.description = f'Training Done'\n",
    "    print(f'Iter: {iteration}, Validating ...')\n",
    "\n",
    "    valid_loss = []\n",
    "    valid_loss_data = []\n",
    "    valid_difference = []\n",
    "    valid_similarity = []\n",
    "    valid_epoch = 0\n",
    "    valid_batch = 0\n",
    "    net.eval()\n",
    "    for indices in events_iter(\n",
    "            batch_size=1, filter_trial_type=filter_trial_type, filter_subject_ids=sub_ids,\n",
    "            custom_filter=valid_custom_filter,\n",
    "            shuffle=False,\n",
    "    ):\n",
    "        valid_loss_data.append(data_events_info[indices][:, [idx_MID, idx_VERSION, idx_SUBID]])\n",
    "        for batch_input, batch_output in testing_iter(indices, window_length=window_length, shuffle=False):\n",
    "            valid_epoch += 1\n",
    "            valid_batch += batch_input.shape[0]\n",
    "            valid_progress.value = valid_epoch\n",
    "            valid_progress.description = f'Validate {valid_epoch}/{max_valid_epoch}'\n",
    "            \n",
    "            # batch_input = (batch_size, number_channel, window_length)\n",
    "            X = th.Tensor(net.transform_input(batch_input)).to(device)\n",
    "            Y = th.Tensor(batch_output).to(device)\n",
    "            \n",
    "            with th.no_grad():\n",
    "                output = net(X)\n",
    "                if net_has_state:\n",
    "                    output, state = output\n",
    "                loss = criterion(output, Y)\n",
    "            \n",
    "            valid_loss.append(loss.item())\n",
    "            \n",
    "            wy = batch_output.flatten()\n",
    "            wx = output.flatten().cpu().numpy()\n",
    "            valid_difference.append(compute_difference(wy, wx))\n",
    "            valid_similarity.append(ssim_criterion(stft_tensor(wx), stft_tensor(wy)).item())\n",
    "    \n",
    "    similarity = np.mean(np.abs(valid_similarity))\n",
    "    difference = np.mean(valid_difference, axis=0)\n",
    "    valid_progress.max = max_valid_epoch = valid_epoch\n",
    "    valid_progress.description = f'Validate Done'\n",
    "    \n",
    "    temp_stats = stats_dict.copy()\n",
    "    temp_stats['iteration'] = iteration\n",
    "    \n",
    "    temp_stats['train_epoch'] = train_epoch\n",
    "    temp_stats['train_batch'] = train_batch\n",
    "    \n",
    "    temp_stats['train_loss'] = np.sum(train_loss)/train_batch  # batch\n",
    "    temp_stats['train_loss_raw'] = np.asarray(train_loss)\n",
    "    temp_stats['train_loss_epoch'] = np.mean(train_loss)\n",
    "    temp_stats['train_loss_batch'] = np.sum(train_loss)/train_batch\n",
    "    \n",
    "    temp_stats['valid_epoch'] = valid_epoch\n",
    "    temp_stats['valid_batch'] = valid_batch\n",
    "    \n",
    "    temp_stats['valid_loss_raw'] = np.asarray(valid_loss)\n",
    "    temp_stats['valid_loss'] = np.sum(valid_loss)/valid_batch  # batch (*best model)\n",
    "    temp_stats['valid_loss_micro'] = np.sum(valid_loss)/valid_batch  # by batch\n",
    "    temp_stats['valid_loss_macro'] = np.mean(valid_loss)  # by number of songs\n",
    "    temp_stats['valid_loss_data'] = np.concatenate(valid_loss_data)\n",
    "    \n",
    "    temp_stats['valid_similarity_raw'] = np.asarray(valid_similarity)\n",
    "    temp_stats['valid_similarity'] = np.mean(np.abs(valid_similarity))  # (*best similar model)\n",
    "    temp_stats['valid_difference_raw'] = np.asarray(valid_difference)\n",
    "    temp_stats['valid_difference'] = difference[3]\n",
    "    \n",
    "    print(f'''====================================================================================================\n",
    "Iter: {iteration},\\tTraining-MAELoss: {temp_stats['train_loss_epoch']*1e6:.3f} / 1e6 (epoch), {temp_stats['train_loss_batch']*1e6:.3f} / 1e6 (batch)\n",
    "\\t\\t Validating-MAELoss: {temp_stats['valid_loss_macro']*1e6:.3f} / 1e6 (song),  {temp_stats['valid_loss_micro']*1e6:.3f} / 1e6 (batch)\n",
    "\\t\\tSimilarity: {similarity:.3f} Difference: {difference[3]:.2f} (Time: {difference[0]:.2f}, Frequency: {difference[1]:.2f}, Power: {difference[2]:.2f})\n",
    "====================================================================================================''')\n",
    "        \n",
    "    if iteration % 20 == 0:\n",
    "        th.save(net.state_dict(), f'experiments/{trial_type}_{MODEL}/model-{MODEL_SIGNATURE}-iter-{iteration:03d}.pt')\n",
    "    \n",
    "    if best_loss is None or temp_stats['valid_loss'] < best_loss:\n",
    "        best_iter = iteration\n",
    "        best_loss = temp_stats['valid_loss']\n",
    "        th.save(net.state_dict(), f'experiments/{trial_type}_{MODEL}/model-{MODEL_SIGNATURE}-best-loss-iter-{best_iter:03d}.pt')\n",
    "    \n",
    "    if best_sim is None or similarity > best_sim:\n",
    "        best_sim_iter = iteration\n",
    "        best_sim = similarity\n",
    "        th.save(net.state_dict(), f'experiments/{trial_type}_{MODEL}/model-{MODEL_SIGNATURE}-best-sim-iter-{best_sim_iter:03d}.pt')\n",
    "        \n",
    "    \n",
    "    temp_stats['best_loss'] = best_loss\n",
    "    temp_stats['best_iteration'] = best_iter\n",
    "    \n",
    "    temp_stats['best_sim'] = best_sim\n",
    "    temp_stats['best_sim_iteration'] = best_sim_iter\n",
    "    \n",
    "    \n",
    "    test_epoch = 0\n",
    "    test_batch = 0\n",
    "    test_loss_data = dict()\n",
    "    test_loss = dict()\n",
    "    test_difference = dict()\n",
    "    test_similarity = dict()\n",
    "    \n",
    "    for test_id, experiment_filter in enumerate(test_filter_list):\n",
    "        test_loss_data[test_id] = []\n",
    "        test_loss[test_id] = []\n",
    "        test_difference[test_id] = []\n",
    "        test_similarity[test_id] = []\n",
    "        \n",
    "        for indices in events_iter(\n",
    "            batch_size=1, filter_trial_type=filter_trial_type, filter_subject_ids=sub_ids,\n",
    "            custom_filter=experiment_filter,\n",
    "            shuffle=False,\n",
    "        ):\n",
    "            test_loss_data[test_id].append(data_events_info[indices][:, [idx_MID, idx_VERSION, idx_SUBID]])\n",
    "            for batch_input, batch_output in testing_iter(indices, window_length=window_length, shuffle=False):\n",
    "                test_epoch += 1\n",
    "                test_batch += batch_input.shape[0]\n",
    "                test_progress.value = test_epoch\n",
    "                test_progress.description = f'Test {test_epoch}/{max_test_epoch}'\n",
    "\n",
    "                # batch_input = (batch_size, number_channel, window_length)\n",
    "                X = th.Tensor(net.transform_input(batch_input)).to(device)\n",
    "                Y = th.Tensor(batch_output).to(device)\n",
    "\n",
    "                with th.no_grad():\n",
    "                    output = net(X)\n",
    "                    if net_has_state:\n",
    "                        output, state = output\n",
    "                    loss = criterion(output, Y)\n",
    "\n",
    "                test_loss[test_id].append(loss.item())\n",
    "\n",
    "                wy = batch_output.flatten()\n",
    "                wx = output.flatten().cpu().numpy()\n",
    "                test_difference[test_id].append(compute_difference(wy, wx))\n",
    "                test_similarity[test_id].append(ssim_criterion(stft_tensor(wx), stft_tensor(wy)).item())\n",
    "    \n",
    "    test_progress.max = max_test_epoch = test_epoch\n",
    "    test_progress.description = f'Test Done'\n",
    "    \n",
    "    temp_stats['test_epoch'] = test_epoch\n",
    "    temp_stats['test_batch'] = test_batch\n",
    "    \n",
    "    temp_stats['test_loss_data'] = test_loss_data\n",
    "    temp_stats['test_loss_raw'] = test_loss\n",
    "    temp_stats['test_difference_raw'] = test_difference\n",
    "    temp_stats['test_similarity_raw'] = test_similarity\n",
    "    \n",
    "    temp_stats['test_loss_micro'] = []\n",
    "    temp_stats['test_loss_macro'] = []\n",
    "    temp_stats['test_difference'] = []\n",
    "    temp_stats['test_similarity'] = []\n",
    "    for test_id in range(len(experiments_list)):\n",
    "        temp_stats['test_loss_micro'].append(np.sum(test_loss[test_id])/test_batch)\n",
    "        temp_stats['test_loss_macro'].append(np.mean(test_loss[test_id]))\n",
    "        temp_stats['test_difference'].append(np.mean(test_difference[test_id], axis=0)[3])\n",
    "        temp_stats['test_similarity'].append(np.mean(np.abs(test_similarity[test_id])))\n",
    "    \n",
    "    stats.append(temp_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f7d77b-0258-4682-8d5a-734ee427235f",
   "metadata": {},
   "source": [
    "## Save Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf7267-8ff8-4a86-9425-24ca4eef0361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(f'experiments/{trial_type}_{MODEL}/stats.npy', stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80437230-d6ec-427c-9ec6-363eac2184e4",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa12cbfd-03db-4017-9da4-6c295b4c24c1",
   "metadata": {},
   "source": [
    "# Load Stats to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f55cc0-eb9f-48b0-be63-55243b0402e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats = list(np.load(f'experiments/{trial_type}_{MODEL}/stats.npy', allow_pickle=True))\n",
    "stats_df = pd.DataFrame(list(stats))\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa72084-6fb2-48c3-be2a-6567368a2f2b",
   "metadata": {},
   "source": [
    "## Training - Validating Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d037d21-b69f-42a5-b559-6ca19472aaf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.subplots()\n",
    "ax.set_title('Mean Absolute Error Plot')\n",
    "line_train = ax.plot(range(1, num_iteration + 1), stats_df['train_loss'], color='tab:blue')\n",
    "line_valid = ax.plot(range(1, num_iteration + 1), stats_df['valid_loss'], color='tab:orange')\n",
    "line_best = ax.vlines(stats_df['best_iteration'], ymin=0, ymax=stats_df['best_loss'], colors='tab:red', linewidth=0.3, linestyles='--')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Mean Absolute Error')\n",
    "ax.set_xticks(range(0, num_iteration + 1, 10))\n",
    "\n",
    "# ax2 = ax.twinx()\n",
    "# line_valid_macro = ax2.plot(range(1, num_iteration + 1), stats_df['valid_loss_macro'], color='tab:green', alpha=.7)\n",
    "\n",
    "ax.legend(line_train + line_valid + [line_best], ['Train', 'Valid', 'best'])\n",
    "\n",
    "# ax.set_ylim(stats_df['train_loss'].min() * .2, stats_df['train_loss'].max() * .6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8d963-4ed6-4aa1-9d48-3587bb7ddafa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax1 = fig.subplots()\n",
    "ax1.set_title('MAE vs Structural Similarity Plot')\n",
    "line_train = ax1.plot(range(1, num_iteration + 1), stats_df['train_loss_raw'].apply(lambda x: np.sum(x))/stats_df['train_batch'], color='tab:blue')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "line_valid = ax2.plot(range(1, num_iteration + 1), stats_df['valid_similarity'], color='tab:orange')\n",
    "line_best = ax2.vlines(stats_df['best_sim_iteration'], ymin=0, ymax=stats_df['best_sim'], colors='tab:red', linewidth=0.3, linestyles='--')\n",
    "\n",
    "ax1.legend(line_train + line_valid + [line_best], ['Train (MAE)', 'Valid (SSIM)', 'Best (SSIM)'])\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Mean Absolute Error', color='tab:blue')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "ax2.set_ylabel('Structural Similarity', color='tab:orange')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:orange')\n",
    "# line_best = ax.vlines(stats_df['best_sim'], ymin=0, ymax=stats_df['best_sim'], colors='tab:green', linewidth=0.3, linestyles='--')\n",
    "\n",
    "ax1.set_xticks(range(0, num_iteration + 1, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4be0c7-c4f5-42be-9a6f-404d9fe59b0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792d9253-a896-4d08-a850-93604834d168",
   "metadata": {},
   "source": [
    "### Known / Unknown / New Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db6def5-e837-4b1c-ab0f-b48b3e4301ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stat_to_plot = np.stack(stats_df['test_loss_micro'].to_numpy())\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.subplots()\n",
    "ax.set_title('Mean Absolute Error Plot - Known vs Unknown vs New-Subject')\n",
    "line_known = ax.plot(range(1, num_iteration + 1), stats_df['valid_loss'], color='tab:blue')\n",
    "line_unknown = ax.plot(range(1, num_iteration + 1), stat_to_plot[:, ID_TEST_NEW_MUSIC], color='tab:orange')\n",
    "line_newsub = ax.plot(range(1, num_iteration + 1), stat_to_plot[:, ID_TEST_NEW_SUB], color='tab:green', alpha=.7)\n",
    "line_best = ax.vlines(stats_df['best_iteration'], ymin=0, ymax=stats_df['best_loss'], colors='tab:red', linewidth=0.3, linestyles='--')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Mean Absolute Error')\n",
    "ax.set_xticks(range(0, num_iteration + 1, 10))\n",
    "\n",
    "ax.legend(line_known + line_newsub + line_unknown + [line_best], ['Known-Songs (Valid)', 'New-Subject', 'Unknown-Songs', 'Best'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe8557-b24f-4bfc-a01e-991f22f7af8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stat_to_plot = np.stack(stats_df['test_similarity'].to_numpy())\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.subplots()\n",
    "ax.set_title('Structural Similarity Plot - Known vs Unknown vs New-Subject')\n",
    "line_known = ax.plot(range(1, num_iteration + 1), stats_df['valid_similarity'], color='tab:blue')\n",
    "line_unknown = ax.plot(range(1, num_iteration + 1), stat_to_plot[:, ID_TEST_NEW_MUSIC], color='tab:orange')\n",
    "line_newsub = ax.plot(range(1, num_iteration + 1), stat_to_plot[:, ID_TEST_NEW_SUB], color='tab:green')\n",
    "line_best = ax.vlines(stats_df['best_sim_iteration'], ymin=0, ymax=stats_df['best_sim'], colors='tab:red', linewidth=0.3, linestyles='--')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Structural Similarity')\n",
    "ax.set_xticks(range(0, num_iteration + 1, 10))\n",
    "\n",
    "ax.legend(line_unknown + line_known + line_newsub + [line_best], ['Unknown-Songs', 'Known-Songs (Valid)', 'New-Subject', 'Best'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4dded5-ff62-4769-9227-51b6f6c19d7d",
   "metadata": {},
   "source": [
    "### By Instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be20d242-f0a0-4d67-9d0f-4cefe2f6ddff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stat_to_plot = np.stack(stats_df['test_loss_macro'].to_numpy())\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.subplots()\n",
    "ax.set_title('Mean Absolute Error Plot - By Instruments')\n",
    "line_celesta = ax.plot(range(1, num_iteration + 1), stat_to_plot[:, ID_TEST_INSTRUMENT_CELESTA], color='tab:blue')\n",
    "line_trombone = ax.plot(range(1, num_iteration + 1), stat_to_plot[:, ID_TEST_INSTRUMENT_TROMBONE], color='tab:orange')\n",
    "line_violin = ax.plot(range(1, num_iteration + 1), stat_to_plot[:, ID_TEST_INSTRUMENT_VIOLIN], color='tab:green', alpha=.7)\n",
    "# line_best = ax.vlines(stats_df['best_iteration'], ymin=0, ymax=stats_df['best_loss'], colors='tab:red', linewidth=0.3, linestyles='--')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Mean Absolute Error')\n",
    "ax.set_xticks(range(0, num_iteration + 1, 10))\n",
    "\n",
    "ax.legend(line_celesta + line_trombone + line_violin, ['Celesta', 'Trombone', 'Violin'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28bfd88-d57e-4675-a1f2-c7109db68e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stat_to_plot = np.stack(stats_df['test_similarity'].to_numpy())\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.subplots()\n",
    "ax.set_title('Structural Similarity Plot - By Instruments')\n",
    "line_celesta = ax.plot(range(1, num_iteration + 1), stat_to_plot[:, ID_TEST_INSTRUMENT_CELESTA], color='tab:blue')\n",
    "line_trombone = ax.plot(range(1, num_iteration + 1), stat_to_plot[:, ID_TEST_INSTRUMENT_TROMBONE], color='tab:orange')\n",
    "line_violin = ax.plot(range(1, num_iteration + 1), stat_to_plot[:, ID_TEST_INSTRUMENT_VIOLIN], color='tab:green', alpha=.7)\n",
    "line_best = ax.vlines(stats_df['best_iteration'], ymin=0, ymax=stats_df['best_loss'], colors='tab:red', linewidth=0.3, linestyles='--')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Structural Similarity')\n",
    "ax.set_xticks(range(0, num_iteration + 1, 10))\n",
    "\n",
    "ax.legend(line_celesta + line_trombone + line_violin + [line_best], ['Celesta', 'Trombone', 'Violin', 'Best'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8072b94a-dc46-467d-ad56-230ae487fbd3",
   "metadata": {},
   "source": [
    "## Recovered Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b406696-8fdd-4c76-b570-4a2f4feb3733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_sample():\n",
    "    sample_event_idx = events_iter(batch_size=batch_size, filter_trial_type=filter_trial_type, filter_subject_ids=sub_ids, shuffle=True)[0][0]\n",
    "    eeg_start, eeg_stop, mid, _, version, _ = data_events_info[sample_event_idx]\n",
    "    sample_music = musics[version][mid]\n",
    "    \n",
    "    eeg_indices = [\n",
    "        np.arange(eeg_start, eeg_stop, window_length),  # EEG-start\n",
    "        np.concatenate([np.arange(eeg_start + window_length, eeg_stop, window_length), [eeg_stop]]) # EEG-stop\n",
    "    ]\n",
    "    batch_input = []\n",
    "    for sample_start, sample_stop in zip(*eeg_indices):\n",
    "        batch_input.append(padding(data_eeg_raw[:, sample_start:sample_stop], window_length=window_length, axis=1))\n",
    "    batch_input = net.transform_input(np.stack(batch_input))\n",
    "    cutoff = eeg_indices[0].shape[0] * music_window_length\n",
    "    sample_wav = padding(sample_music['wav-low'][:cutoff], cutoff)\n",
    "    with th.no_grad():\n",
    "        outputs = net(th.Tensor(batch_input).to(device))\n",
    "        if net_has_state:\n",
    "            outputs, states = outputs\n",
    "        predict_wav = outputs.flatten().cpu().numpy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 9))\n",
    "    axes = fig.subplots(nrows=3)\n",
    "\n",
    "    axes[0].plot(sample_wav, color='tab:blue')\n",
    "    axes[0].plot(predict_wav, color='tab:orange')\n",
    "    axes[0].set_title('Music wave')\n",
    "    axes[0].set_xticks([])\n",
    "\n",
    "    org_D = librosa.amplitude_to_db(np.abs(librosa.stft(sample_wav, n_fft=64)), ref=np.max)\n",
    "    pred_D = librosa.amplitude_to_db(np.abs(librosa.stft(predict_wav, n_fft=64)), ref=np.max)\n",
    "    librosa.display.specshow(org_D, y_axis='linear', ax=axes[1])\n",
    "    librosa.display.specshow(pred_D, y_axis='linear',  ax=axes[2])\n",
    "    axes[1].set(title='Original - Spectrogram')\n",
    "    axes[2].set(title='Predict - Spectrogram')\n",
    "    plt.show()\n",
    "    \n",
    "    return sample_wav, predict_wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c42479b-6db0-4a4b-8c5a-cef0a4e87481",
   "metadata": {
    "tags": []
   },
   "source": [
    "### By Best Similarity Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f34f88-f2f0-4f98-89c5-f1df7a2a60bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net.load_state_dict(th.load(f'experiments/{trial_type}_{MODEL}/model-{MODEL_SIGNATURE}-best-sim-iter-{best_sim_iter:03d}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1690d99-866f-4614-b00f-e53d8b0df42e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_sample();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0fb795-9b8d-4a73-b328-1eddaa3cad4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_sample();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc409756-bd70-4e5e-a21d-94da7c244e21",
   "metadata": {},
   "source": [
    "### By Best Loss Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b030b-e2f5-4e26-9bca-c0a2df3c4e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net.load_state_dict(th.load(f'experiments/{trial_type}_{MODEL}/model-{MODEL_SIGNATURE}-best-loss-iter-{best_iter:03d}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d07dc-8944-41e8-bcb3-6f78db101d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_sample();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a168123-67bd-4df6-94a7-883476e33a78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_sample();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d569f54-0995-48c0-b66b-84c1238d7cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
